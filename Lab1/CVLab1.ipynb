{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KydTQgmuSyq-"
      },
      "source": [
        "# Lab 1: Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUUnHHTYSyrA"
      },
      "source": [
        "### Task 1: Preprocessing and Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66zQlsUASyrB"
      },
      "source": [
        "* **STEP 1:** Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkEqMmwKSyrB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers, applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.warn(\"this will not show\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-__L1AkbSyrC"
      },
      "outputs": [],
      "source": [
        "# Data augmentation\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    keras.layers.RandomRotation(factor=0.2),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3)),\n",
        "    layers.RandomBrightness(factor=0.1),\n",
        "    layers.RandomContrast(factor=0.1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-Z2SRWJSyrD"
      },
      "outputs": [],
      "source": [
        "datagenerator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # Assuming you want to split 20% for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqF6QpQ5SyrD",
        "outputId": "87865ebd-dac2-4553-d170-01e72fdbd74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2198 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_generator = datagenerator.flow_from_directory(\n",
        "    \"FlowersDataset//train\",\n",
        "    target_size=(300,300),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWabFcB0SyrE",
        "outputId": "5615e3d2-2045-46c1-844b-a0df3d75c18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 548 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "valid_generator = datagenerator.flow_from_directory(\n",
        "    \"FlowersDataset//train\",\n",
        "    target_size=(300, 300),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDXpq2y_SyrE"
      },
      "outputs": [],
      "source": [
        "# Customizing the model based on InceptionV3\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw98neBJSyrF"
      },
      "outputs": [],
      "source": [
        "# Initializing InceptionV3 (pretrained) model with input image shape as (300, 300, 3)\n",
        "base_model = InceptionV3(weights=None, include_top=False, input_shape=(300, 300, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bixa0WQwSyrF"
      },
      "outputs": [],
      "source": [
        "base_model.load_weights('\\\\kaggle\\\\input\\\\inceptionv3\\\\inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
        "# Setting the Training of all layers of InceptionV3 model to false\n",
        "base_model.trainable = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR_LdB5eSyrG"
      },
      "source": [
        "# Draft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcN1xnveSyrG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "# from keras import ops\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.python.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfiQ0nbrSyrH"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCprrC8cSyrH"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained model from TensorFlow Hub\n",
        "num_classes = 5\n",
        "module_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaxhKYLASyrH"
      },
      "outputs": [],
      "source": [
        "base_model=hub.KerasLayer(module_url, trainable=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soh56qmESyrI"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "#keras.layers.Dense(num_classes, activation='softmax')  # num_classes is the number of classes in your dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgIlS73XSyrI"
      },
      "outputs": [],
      "source": [
        "model.add(base_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNtg_4cbSyrI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and preprocess the dataset\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/Ali/Downloads/labs/lab1/fdataset/train',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/Ali/Downloads/labs/lab1/fdataset/val',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# Configure the dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "epochs = 10 # Adjust the number of epochs as needed\n",
        "history = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
        "\n",
        "# Evaluate the model\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'C:/Users/Ali/Downloads/labs/lab1/fdataset/train',\n",
        "    seed=123,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "model.evaluate(test_dataset)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}